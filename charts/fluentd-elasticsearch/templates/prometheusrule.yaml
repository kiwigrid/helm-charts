{{- if .Values.prometheusRule.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ template "fluentd-elasticsearch.fullname" . }}
  labels:
    app.kubernetes.io/name: {{ include "fluentd-elasticsearch.name" . }}
    helm.sh/chart: {{ include "fluentd-elasticsearch.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    {{- if .Values.prometheusRule.labels }}
    {{- toYaml .Values.prometheusRule.labels | nindent 4 }}
    {{- end }}
  namespace: {{ .Values.prometheusRule.prometheusNamespace }}
spec:
  groups:
  - name: fluentd
    rules:
    - alert: FluentdNodeDown
      expr: up{job="{{ include "fluentd-elasticsearch.fullname" . }}"} == 0
      for: 10m
      labels:
        service: fluentd
        severity: warning
      annotations:
        summary: fluentd cannot be scraped
        description: Prometheus could not scrape {{ "{{ $labels.job }}" }} for more than 10 minutes
  
    - alert: FluentdNodeDown
      expr: up{job="{{ include "fluentd-elasticsearch.fullname" . }}"} == 0
      for: 30m
      labels:
        service: fluentd
        severity: critical
      annotations:
        summary: fluentd cannot be scraped
        description: Prometheus could not scrape {{ "{{ $labels.job }}" }} for more than 30 minutes
  
    - alert: FluentdQueueLength
      expr: rate(fluentd_status_buffer_queue_length[5m]) > 0.3
      for: 1m
      labels:
        service: fluentd
        severity: warning
      annotations:
        summary: fluentd node are failing
        description: In the last 5 minutes, fluentd queues increased 30%. Current value is {{ "{{ $value }}" }}

    - alert: FluentdQueueLength
      expr: rate(fluentd_status_buffer_queue_length[5m]) > 0.5
      for: 1m
      labels:
        service: fluentd
        severity: critical
      annotations:
        summary: fluentd node are critical
        description: In the last 5 minutes, fluentd queues increased 50%. Current value is {{ "{{ $value }}" }}

    - alert: FluentdRecordsCountsHigh
      expr: sum(rate(fluentd_record_counts{job="{{ .Release.Name }}"}[5m])) BY (instance) >  (3 * sum(rate(fluentd_record_counts{job="{{ .Release.Name }}"}[15m])) BY (instance))
      for: 1m
      labels:
        service: fluentd
        severity: critical
      annotations:
        summary: fluentd records count are critical
        description: In the last 5m, records counts increased 3 times, comparing to the latest 15 min.

{{- end }}
